# Ollama モデル推奨 & タイムアウト改善

## 目的・ゴール

1. 実際のプロンプト（翻訳・要約）を使って複数の Ollama モデルを評価し、README におすすめモデルを 3 つ記載する
2. gemma3 モデルで発生するタイムアウト問題（Issue #50）の解決策を検討・実装する

## 実装方針

### モデル評価

- `src/translator.ts` と `src/summarizer.ts` のシステムプロンプト + 実際のユーザー入力を使用
- 評価軸: レスポンス速度、翻訳/要約品質、タイムアウト耐性
- 候補モデル: gemma3, phi4-mini, qwen3:1.7b, llama3.2, gemma3:1b, qwen3:0.6b, llama3.2:1b

### タイムアウト問題

- gemma3 (4B) はデフォルト 30 秒でタイムアウトする場合がある
- 解決策: デフォルト timeoutMs の引き上げ、もしくはより軽量なモデルの推奨

### README 更新

- Recommended Models セクションを追加
- 各モデルの特徴（速度・品質トレードオフ）を簡潔に記載

## 完了条件

- [x] 複数モデルでの翻訳・要約テスト実施
- [x] README に推奨モデル 3 つを記載
- [x] gemma3 タイムアウト問題の解決策を実装
- [x] `npm run build` / `npm run lint` / `npm test` がパス

## 作業ログ

### モデル評価結果

| モデル | 翻訳品質 | 要約品質 | 速度 | 判定 |
|--------|----------|----------|------|------|
| gemma3 (4B) | 良好 | 優秀 | 4〜15秒 | 推奨 |
| phi4-mini (3.8B) | 普通 | 不十分 | 8〜114秒 | 非推奨（遅い） |
| qwen3:1.7b | 普通 | 不十分 | 39〜106秒 | 非推奨（thinking 込みで遅すぎる） |
| llama3.2 (3B) | 不良（ローマ字出力） | 良好 | 3〜30秒 | 要約のみ可 |

### 軽量モデル追加評価（第2ラウンド）

| モデル | 翻訳品質 | 要約品質 | 速度 | 判定 |
|--------|----------|----------|------|------|
| gemma3:1b | 不良（翻訳拒否/未翻訳） | 良好 | 2〜6秒 | 要約のみ推奨（最速） |
| qwen3:0.6b | 普通（thinking残留） | 普通 | 10〜14秒 | 非推奨（thinking遅延） |
| llama3.2:1b | 不良（コード生成） | 不十分 | 2〜10秒 | 非推奨 |

### 実施した変更

1. **デフォルトタイムアウト引き上げ**: `DEFAULT_TIMEOUT_MS` を 30秒 → 60秒に変更（translator.ts, summarizer.ts）
2. **README 更新**: Recommended Ollama models セクションを追加、Full example と Options reference の timeoutMs デフォルト値を 60000 に更新
